searchState.loadedDescShard("opendal", 0, "Apache OpenDAL™ is a data access layer that allows users …\nThe accessor that built by this builder.\n[alluxio][created::services::Alluxio]: Alluxio services.\nThe given path already exists thus we failed to the …\natomicserver: Atomicserver services.\nazblob: Azure Storage Blob services.\nAzdls: Azure Data Lake Storage Gen2.\n[azfile][crate::services::azfile]: Azfile Services\nB2: Backblaze B2 Services.\nBlockingLister is designed to list entries at given path …\nBlockingOperator is the entry for all public blocking APIs.\nBlockingReader is designed to read data from given path in …\nBlockingWriter is designed to write data into given path …\nBuffer is a wrapper of contiguous <code>Bytes</code> and non contiguous …\nBufferSink is the adapter of [<code>Sink</code>] generated by <code>Writer</code>.\nBuilder is used to set up a real underlying service, i.e. …\ncacache: cacache backend support.\nKey for cache control.\nCapability is used to describe what operations are …\nChainsafe: Chainsafe Services.\ncloudflare-kv: Cloudflare KV services.\nCompfs: Compio fs Services.\nThe special metadata key that used to mark this entry …\nThe condition of this operation is not match.\nThe config for backend is invalid.\nKey for content disposition.\nThe content is incomplete.\nKey for content length.\nKey for content md5.\nKey for content range.\nThe content is truncated.\nKey for content type.\ncos: Tencent Cloud Object Storage services.\nCustom that allow users to implement services outside of …\nd1: D1 services\nDIR means the path can be listed.\ndashmap: dashmap backend support.\ndbfs: DBFS backend support.\ndropbox: Dropbox services.\nEntry returned by <code>Lister</code> or <code>BlockingLister</code> to represent a …\nEntryMode represents the mode.\nContains the error value\nError is the error struct returned by all opendal …\nErrorKind is all kinds of Error of opendal.\nKey for etag.\netcd: Etcd Services\nFILE means the path has data to read.\nfoundationdb: Foundationdb services.\nfs: POSIX alike file system.\nftp: FTP backend.\nFuturesAsyncReader is the adapter of <code>AsyncRead</code>, …\nFuturesIoAsyncWriter is the adapter of <code>AsyncWrite</code> for …\nFuturesBytesSink is the adapter of [<code>Sink</code>] generated by …\nFuturesBytesStream is the adapter of <code>Stream</code> generated by …\ngcs: Google Cloud Storage backend.\ngdrive: GoogleDrive services.\nghac: GitHub Action Cache services.\nGithub Contents: Github contents support.\ngridfs: MongoDB Gridfs Services\nhdfs: Hadoop Distributed File System.\nNative HDFS: Hdfs Native service, using rust hdfs-native …\nhttp: HTTP backend.\nhuggingface: Huggingface services.\nicloud: APPLE icloud services.\nThe input is invalid.\nipmfs: IPFS HTTP Gateway\nipmfs: IPFS mutable file system\nThe given path is a directory.\nThe given file paths are same.\nKoofr: Koofr Services.\nKey for last modified.\nlibsql: Libsql services\nLister is designed to list entries at given path in an …\nmemcached: Memcached service support.\nmemory: In memory backend support.\nMetadata carries all metadata associated with a path.\nMetakey describes the metadata keys that can be stored or …\nmini-moka: Mini Moka backend support.\nKey for mode.\nmoka: moka backend support.\nmongodb: MongoDB Services\nmysql: Mysql services\nThe given path is not a directory.\nThe given path is not found.\nobs: Huawei Cloud OBS services.\nContains the success value\nonedrive: Microsoft OneDrive services.\nOperator is the entry for all public async APIs.\nOperatorBuilder is a typed builder to build an Operator.\nMetadata for operator, users can use this metadata to get …\noss: Aliyun Object Storage Services\nPcloud: Pcloud Services.\nThe given path doesn’t have enough permission for this …\npersy: persy backend support.\npostgresql: Postgresql services\nRequests that sent to this path is over the limit, please …\nReader is designed to read data from given path in an …\nredb: Redb Services\nredis: Redis services\nResult that is a wrapper of <code>Result&lt;T, opendal::Error&gt;</code>\nrocksdb: RocksDB services\ns3: AWS S3 alike services.\nAssociated scheme for this builder. It indicates what …\nServices that OpenDAL supports\nSeafile: Seafile Services.\nsftp: SFTP services\nsled: Sled services\nsqlite: Sqlite services\nStdIterator is the adapter of <code>Iterator</code> for <code>BlockingReader</code>.\nStdReader is the adapter of <code>Read</code>, <code>Seek</code> and <code>BufRead</code> for …\nStdWriter is the adapter of <code>std::io::Write</code> for …\nSupabase: Supabase storage service\nsurrealdb: Surrealdb Services\nswift: Swift backend support.\n[tikv][crate::services::tikv]: Tikv Services\nOpenDAL don’t know what happened here, and no actions …\nUnknown means we don’t know what we can do on this path.\nUnderlying service doesn’t support this operation.\nUpyun: Upyun Services.\nVercel Artifacts: Vercel Artifacts service, as known as …\nVercelBlob: VercelBlob Services.\nKey for version.\nwebdav: WebDAV support.\nwebhdfs: WebHDFS RESTful API Services\nWriter is designed to write data into given path in an …\nYandexDisk: YandexDisk Services.\nAbort the writer and clean up all written data.\nIf operator supports batch.\nIf operator supports batch delete.\nThe max operations that operator supports in batch.\nCreate a new blocking operator.\nIf operator supports blocking.\nConsume the accessor builder to build a service.\nCache control of this entry. Cache-Control is defined by …\nCheck if this operator can work correctly.\nClose the writer and make sure all data have been …\nClose the writer and make sure all data have been stored.\nClose the internal writer and make sure all data have been …\nContent-Disposition of this entry\nContent length of this entry.\nContent MD5 of this entry.\nContent Range of this entry.\nContent Type of this entry.\nCopy a file from <code>from</code> to <code>to</code>.\nCopy a file from <code>from</code> to <code>to</code>.\nIf operator supports copy.\nNumber of <code>Bytes</code> in <code>Buffer</code>.\nCreate a dir at given path.\nCreate a dir at given path.\nIf operator supports create dir.\nGet current <code>Bytes</code>.\nDelete the given path.\nDelete given path.\nIf operator supports delete.\nDelete the given path with extra options.\nDelete given path with options.\nThis module holds documentation for OpenDAL.\nGet all enabled schemes.\nETag of this entry.\nFetch specific ranges from reader.\nFinish the building to construct an Operator.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nConstruct a builder from given map which contains several …\nCreate a new operator from given map.\nGet [<code>Full Capability</code>] of operator.\nGet information of underlying accessor.\nGet information of underlying accessor.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConvert reader into <code>StdBytesIterator</code> which implements …\nConvert writer into <code>FuturesBytesSink</code> which implements …\nConvert reader into <code>FuturesBytesStream</code> which implements …\nConvert reader into <code>FuturesAsyncReader</code> which implements …\nConvert writer into <code>FuturesAsyncWriter</code> which implements …\nConsume this entry to get it’s path and metadata.\nConvert self into static str.\nConvert self into static str.\nConvert reader into <code>StdReader</code> which implements …\nConvert writer into <code>StdWriter</code> which implements …\nCheck if this mode is DIR.\nReturns <code>true</code> if this metadata is for a directory.\nCheck if buffer is empty.\nCheck if this path exists or not.\nCheck if this path exists or not.\nCheck if this mode is FILE.\nReturns <code>true</code> if this metadata is for a file.\nCheck if this error is temporary.\nReturn error’s kind.\nLast modified of this entry.\nCreate a new layer with static dispatch.\nCreate a new layer with dynamic dispatch.\n<code>Layer</code> is the mechanism to intercept operations.\nGet the length of the buffer.\nGet current operator’s limit. Limit is usually the …\nGet current operator’s limit\nList entries that starts with given <code>path</code> in parent dir.\nList entries that starts with given <code>path</code> in parent dir.\nIf operator supports list.\nList entries that starts with given <code>path</code> in parent dir …\nList entries that starts with given <code>path</code> in parent dir. …\nIf backend supports list with limit.\nIf backend supports list with recursive.\nIf backend supports list with start after.\nList entries that starts with given <code>path</code> in parent dir.\nList entries that starts with given <code>path</code> in parent dir.\nList entries that starts with given <code>path</code> in parent dir …\nList entries within a given directory as an iterator with …\nOperate on error with map.\nFetch metadata of this entry.\nGet the metakey from metadata.\nmode represent this entry’s mode.\nName of entry. Name is the last segment of path.\nName of backend, could be empty if underlying backend doesn…\nGet [<code>Native Capability</code>] of operator.\nCreate a new operator builder.\nCreate a new Error with error kind and message.\nCreate a new empty buffer.\nCreate a new metadata\nCreate a new operator with input builder.\nFunctions provides the functions generated by …\nFutures provides the futures generated by <code>Operator</code>\nPath of entry. Path is relative to operator’s root.\nIf operator supports presign.\nPresign an operation for read.\nIf operator supports presign read.\nPresign an operation for read with extra options.\nPresign an operation for stat(head).\nIf operator supports presign stat.\nPresign an operation for stat(head).\nPresign an operation for write.\nIf operator supports presign write.\nPresign an operation for write with extra options.\nRaw modules provide raw APIs that used by underlying …\nRead give range from reader into <code>Buffer</code>.\nRead give range from reader into <code>Buffer</code>.\nRead the whole path into a bytes.\nRead the whole path into a bytes.\nIf operator supports read.\nThis operation will copy and write bytes into given <code>BufMut</code>…\nRead all data from reader into given <code>BufMut</code>.\nRead the whole path into a bytes with extra options.\nRead the whole path into a bytes with extra options.\nIf operator supports read with if match.\nIf operator supports read with if none match.\nif operator supports read with override cache control.\nif operator supports read with override content …\nif operator supports read with override content type.\nCreate a new reader which can read the whole path.\nCreate a new reader which can read the whole path.\nCreate a new reader with extra options\nCreate a new reader with extra options\nNotes\nNotes\nRemove the path and all nested dirs and files recursively.\nRemove the path and all nested dirs and files recursively.\nremove will remove files via the given paths.\nremove will remove files via the given paths.\nRename a file from <code>from</code> to <code>to</code>.\nRename a file from <code>from</code> to <code>to</code>.\nIf operator supports rename.\nRoot of operator, will be in format like <code>/path/to/dir/</code>\n<code>Scheme</code> of operator.\nServices will provide builders to build underlying …\nSet cache control of this entry.\nSet Content-Disposition of this entry\nSet content length of this entry.\nSet content MD5 of this entry.\nSet Content Range of this entry.\nSet Content Type of this entry.\nSet ETag of this entry.\nSet Last modified of this entry.\nSet mode for entry.\nSet permanent status for error.\nSet persistent status for error.\nSet source for error.\nSet temporary status for error.\nSet version of this entry.\nReturns a slice of self for the provided range.\nGet given path’s metadata.\nGet given path’s metadata.\nIf operator supports stat.\nGet given path’s metadata with extra options.\nGet given path’s metadata with extra options.\nIf operator supports stat with if match.\nIf operator supports stat with if none match.\nif operator supports read with override cache control.\nif operator supports read with override content …\nif operator supports read with override content type.\nCombine all bytes together into one single <code>Bytes</code>.\nConvert buffer into a slice of <code>IoSlice</code> for vectored write.\nCombine all bytes together into one single <code>Vec&lt;u8&gt;</code>.\nShortens the buffer, keeping the first <code>len</code> bytes and …\nVersion of this entry.\nCreate a new operator from given scheme and map.\nSet cache control of this entry.\nSet the capacity of this reader to control the IO size.\nSet the capacity of this reader to control the IO size.\nSet Content-Disposition of this entry\nSet content length of this entry.\nSet content MD5 of this entry.\nSet Content Range of this entry.\nSet Content Type of this entry.\nAdd more context in error.\nSet ETag of this entry.\nSet Last modified of this entry.\nSpecify the batch limit.\nSpecify the batch limit.\nSet mode for entry.\nUpdate error’s operation.\nSet version of this entry.\nWrite <code>Buffer</code> into writer.\nWrite into inner writer.\nWrite bytes into path.\nWrite bytes into given path.\nIf operator supports write.\nIf operator supports write by append.\nIf operator supports write with empty content.\nIf operator supports write can be called in multi times.\nWrite <code>bytes::Buf</code> into inner writer.\nwrite_multi_align_size is the align size that services …\nwrite_multi_max_size is the max size that services support …\nwrite_multi_min_size is the min size that services support …\nwrite_total_max_size is the max size that services support …\nWrite data with extra options.\nWrite data with option described in OpenDAL RFC-0661\nIf operator supports write with cache control.\nIf operator supports write with content disposition.\nIf operator supports write with content type.\nWrite multiple bytes into path.\nWrite multiple bytes into given path.\nWrite multiple bytes into path with extra options.\nCreate a new reader with extra options\nChanges log for all OpenDAL released versions.\nCompare opendal with other projects to find out the …\nThe core concepts of OpenDAL’s public API.\nThe internal implement details of OpenDAL.\nRFCs - OpenDAL Active RFC List\nUpgrade and migrate procedures while OpenDAL meets …\nOpenDAL vs object_store\nThe internal implementation details of <code>Access</code>.\nThe internal implementation details of <code>Layer</code>.\nRFC example\nObject native API\nError handle\nAuto region\nObject stream\nLimited reader\nPath normalization\nAsync streaming IO\nRemove credential\nCreate dir\nRetryable error\nObject ID\nDir entry\nAccessor capabilities\nPresign\nCommand line interface\nInit from iter\nMultipart\nGateway\nNew builder\nWrite refactor\nList metadata reuse\nBlocking API\nRedis service\nSplit capabilities\nPath in accessor\nGeneric KV services\nObject reader\nRefactor error\nObject handler\nObject metadataer\nQuery based metadata\nObject writer\nRemove object concept\nOperation extension\nWriter sink API\nAppend API\nChain based operator API\nObject versioning\nMerge append into write\nLister API\nList with metakey\nNative capability\nRemove write copy from\nConfig\nAlign list API\nList prefix\nLazy reader\nList recursive\nConcurrent stat in list\nBuffered Reader\nConcurrent Writer\nDeleter API\nRange Based Read API\nAdd Efficient, logical ‘stack’ traces of async …\nAdd a Instrument await-tree for actor-based applications …\nAdd blocking API support for non-blocking services.\nInject chaos into underlying services for robustness test.\nAdd concurrent request limit.\nSupport User Statically-Defined Tracing(aka USDT) on Linux\nAdd an immutable in-memory index for underlying storage …\nAdd log for every operations.\nAdd deterministic simulation for async operations, powered …\nA simulated server.This an experimental feature, docs are …\nAdd metrics for every operations.\nAdd minitrace for every operations.\nAdd opentelemetry::trace for every operations.\nAdd prometheus for every operations.\nAdd prometheus for every operations.\nRetryInterceptor is used to intercept while retry happened.\nAdd retry for temporary failed operations.\nAdd a bandwidth rate limiter to the underlying services.\nAdd timeout for every operations to avoid slow or …\nAdd tracing for every operations.\nset buckets for bytes_total\nCreate a new <code>BlockingLayer</code> with the current runtime’s …\nset path label level 0: no path label, the path label will …\nInsert keys from iter.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nInsert a key into index.\nEverytime RetryLayer is retrying, this function will be …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate a new retry layer.\nCreate a new ConcurrentLimitLayer will specify permits\nCreate a new <code>TimeoutLayer</code> with default settings.\nCreate a new chaos layer with specified error ratio.\nCreate PrometheusClientLayer while registering itself to …\nCreate new madsim layer\nCreate a new <code>ThrottleLayer</code> with given bandwidth and burst.\nCreate a new <code>AwaitTreeLayer</code>.\nset buckets for requests_duration_seconds\nStart serving as madsim server.\nSetting whether to output backtrace while unexpected …\nSetting the log level while expected error happened.\nSet factor of current backoff.\nSetting the log level while unexpected failure happened.\nSet io timeout for TimeoutLayer with given value.\nSet jitter of current backoff.\nSet max_delay of current backoff.\nSet max_times of current backoff.\nSet min_delay of current backoff.\nSet the retry interceptor as new notify.\ncreate PrometheusLayer by incoming registry.\nSet speed for TimeoutLayer with given value.\nSet timeout for TimeoutLayer with given value.\nFunction that generated by <code>BlockingOperator::delete_with</code>.\nFunction that generated by <code>BlockingOperator::list_with</code>.\nFunction that generated by <code>BlockingOperator::lister_with</code>.\nFunction that generated by <code>BlockingOperator::read_with</code>.\nFunction that generated by <code>BlockingOperator::reader_with</code>.\nFunction that generated by <code>BlockingOperator::stat_with</code>.\nFunction that generated by <code>BlockingOperator::write_with</code>.\nFunction that generated by <code>BlockingOperator::writer_with</code>.\nSet the append mode of op.\nSet the append mode of op.\nSet the buffer size of op.\nSet the content type of option\nSet the content type of option\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nCall the function to consume all the input and generate a …\nSet the chunk size of op.\nSet the content disposition of option\nSet the content disposition of option\nSet the content type of option\nSet the content type of option\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nSet the If-Match for this operation.\nSet the If-Match for this operation.\nSet the If-None-Match for this operation.\nSet the If-None-Match for this operation.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe limit passed to underlying service to specify the max …\nThe limit passed to underlying service to specify the max …\nMetakey is used to control which meta should be returned.\nMetakey is used to control which meta should be returned.\nSets the cache-control header that should be send back by …\nSets the content-disposition header that should be send …\nSets the content-type header that should be send back by …\nSet the range for this operation.\nThe recursive is used to control whether the list …\nThe recursive is used to control whether the list …\nThe start_after passes to underlying service to specify …\nThe start_after passes to underlying service to specify …\nSet the version for this operation.\nSet the version for this operation.\nSet the version for this operation.\nFuture that generated by <code>Operator::delete_with</code>.\nFuture that generated by <code>Operator::list_with</code> or …\nFuture that generated by <code>Operator::list_with</code> or …\nFuture that generated by <code>Operator::presign_read_with</code>.\nFuture that generated by <code>Operator::presign_stat_with</code>.\nFuture that generated by <code>Operator::presign_write_with</code>.\nFuture that generated by <code>Operator::read_with</code> or …\nFuture that generated by <code>Operator::read_with</code> or …\nFuture that generated by <code>Operator::stat_with</code>.\nFuture that generated by <code>Operator::write_with</code>.\nFuture that generated by <code>Operator::writer_with</code>.\nOperatorFuture is the future generated by <code>Operator</code>.\nSet the append mode of op.\nSet the append mode of op.\nSet the append mode of op.\nSet the append mode of op.\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the chunk size of op.\nSet the chunk size for this reader.\nSet the chunk size for this operation.\nSet the buffer size of op.\nSet the chunk size for this operation.\nSet the chunk size for this reader.\nSet the buffer size of op.\nSet the chunk size of op.\nSet the concurrent read task amount.\nSet the maximum concurrent write task amount.\nConcurrent is used to control the number of concurrent …\nSet the concurrent read task amount.\nSet the maximum concurrent write task amount.\nConcurrent is used to control the number of concurrent …\nSet the concurrent read task amount.\nSet the concurrent read task amount.\nSet the maximum concurrent write task amount.\nSet the maximum concurrent write task amount.\nConcurrent is used to control the number of concurrent …\nConcurrent is used to control the number of concurrent …\nSet the content disposition of option\nSet the content disposition of option\nSet the content disposition of option\nSet the content disposition of option\nSet the content disposition of option\nSet the content disposition of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nReturns the argument unchanged.\nSet the gap size for this reader.\nSet the gap size for this reader.\nSet the If-Match of the option\nSet the If-Match for this operation.\nSet the If-Match of the option\nSet the If-Match for this operation.\nSet the If-Match for this operation.\nSet the If-Match of the option\nSet the If-Match of the option\nSet the If-Match for this operation.\nSet the If-None-Match of the option\nSet the If-None-Match for this operation.\nSet the If-None-Match for this operation.\nSet the If-None-Match of the option\nSet the If-None-Match for this operation.\nSet the If-None-Match of the option\nSet the If-None-Match of the option\nSet the If-None-Match for this operation.\nCalls <code>U::from(self)</code>.\nThe limit passed to underlying service to specify the max …\nThe limit passed to underlying service to specify the max …\nThe limit passed to underlying service to specify the max …\nThe limit passed to underlying service to specify the max …\nMetakey is used to control which meta should be returned.\nMetakey is used to control which meta should be returned.\nMetakey is used to control which meta should be returned.\nMetakey is used to control which meta should be returned.\nSets the cache-control header that should be send back by …\nSets the cache-control header that should be send back by …\nSets the cache-control header that should be send back by …\nSets the cache-control header that should be send back by …\nSets the content-disposition header that should be send …\nSets the content-disposition header that should be send …\nSets the content-disposition header that should be send …\nSets the content-disposition header that should be send …\nSets the content-type header that should be send back by …\nSets the content-type header that should be send back by …\nSets the content-type header that should be send back by …\nSets the content-type header that should be send back by …\nSet the range header for this operation.\nSet the range header for this operation.\nThe recursive is used to control whether the list …\nThe recursive is used to control whether the list …\nThe recursive is used to control whether the list …\nThe recursive is used to control whether the list …\nThe start_after passes to underlying service to specify …\nThe start_after passes to underlying service to specify …\nThe start_after passes to underlying service to specify …\nThe start_after passes to underlying service to specify …\nChange the version of this delete operation.\nSet the version for this operation.\nSet the version for this operation.\nSet the version for this operation.\nSet the version for this operation.\nSet the version for this operation.\nSet the version for this operation.\nChange the version of this delete operation.\nUnderlying trait of all backends for implementers.\n<code>AccessDyn</code> is the dyn version of <code>Access</code> make it possible to …\nAccessor is the type erased accessor with <code>Arc&lt;dyn Accessor&gt;</code>…\nMetadata for accessor, users can use this metadata to get …\nOperation for <code>crate::raw::Access::batch</code>\nBatch operation used for batch.\nBatch results of <code>batch</code> operations.\nOperation for <code>crate::raw::Access::blocking_copy</code>\nOperation for <code>crate::raw::Access::blocking_create_dir</code>\nOperation for <code>crate::raw::Access::blocking_delete</code>\nOperation for <code>crate::raw::Access::blocking_list</code>\nBlockingLister is the associated lister returned …\nOperation for <code>crate::raw::Access::blocking_read</code>\nBlockingReader is the associated reader returned …\nOperation for <code>crate::raw::Access::blocking_rename</code>\nOperation for <code>crate::raw::Access::blocking_stat</code>\nOperation for <code>crate::raw::Access::blocking_write</code>\nBlockingWriter is the associated writer returned …\nBoxedFuture is the type alias of <code>futures::future::BoxFuture</code>…\nBoxedStaticFuture is the type alias of …\nBytesContentRange is the content range of bytes.\nBytesRange(offset, size) carries a range of content.\nConcurrentFutures is a stream that can hold a stream of …\nConfigDeserializer is used to deserialize given configs …\nOperation for <code>crate::raw::Access::copy</code>\nOperation for <code>crate::raw::Access::create_dir</code>\nresults of <code>delete batch</code> operation\nOperation for <code>crate::raw::Access::delete</code>\nBatch delete operation.\nFormDataPart is a builder for multipart/form-data part.\nThe fourth type for the <code>FourWays</code>.\nFourWays is used to implement traits that based on four …\nHttpClient that used across opendal.\nOperation for <code>crate::raw::Access::info</code>\nLayer is used to intercept the operations on the …\nLayeredAccess is layered accessor that forward all not …\nThe layered accessor that returned by this layer.\nOperation for <code>crate::raw::Access::list</code>\nLister is the associated lister returned in <code>list</code> operation.\nMaybeSend is a marker to determine whether a type is <code>Send</code> …\nMixedPart is a builder for multipart/mixed part.\nMultipart is a builder for multipart/form-data.\nThe first type for the <code>TwoWays</code>.\nThe first type for the <code>ThreeWays</code>.\nThe first type for the <code>FourWays</code>.\nArgs for <code>batch</code> operation.\nArgs for <code>copy</code> operation.\nArgs for <code>create</code> operation.\nArgs for <code>delete</code> operation.\nArgs for <code>list</code> operation.\nArgs for <code>presign</code> operation.\nArgs for <code>read</code> operation.\nArgs for reader operation.\nArgs for <code>rename</code> operation.\nArgs for <code>stat</code> operation.\nArgs for <code>write</code> operation.\nOperation is the name for APIs in <code>Accessor</code>.\nPart is a trait for multipart part.\nPathCacher is a cache for path query.\nThe trait required for path cacher.\nOperation for <code>crate::raw::Access::presign</code>\nPresign operation used for presign.\nPresignedRequest is a presigned request return by <code>presign</code>.\nOperation for <code>crate::raw::Access::read</code>\nPresign a read operation.\nReader is the associated reader returned in <code>read</code> operation.\nOperation for <code>crate::raw::Access::rename</code>\nReply for <code>batch</code> operation.\nReply for <code>copy</code> operation.\nReply for <code>create_dir</code> operation\nReply for <code>delete</code> operation\nReply for <code>list</code> operation.\nReply for <code>presign</code> operation.\nReply for <code>read</code> operation.\nReply for <code>rename</code> operation.\nReply for <code>stat</code> operation.\nReply for <code>write</code> operation.\nOperation for <code>crate::raw::Access::stat</code>\nPresign a stat(head) operation.\nTYPE is the type of multipart.\nThe third type for the <code>ThreeWays</code>.\nThe third type for the <code>FourWays</code>.\nThreeWays is used to implement traits that based on three …\nThe second type for the <code>TwoWays</code>.\nThe second type for the <code>ThreeWays</code>.\nThe second type for the <code>FourWays</code>.\nTwoWays is used to implement traits that based on two ways.\nVERSION is the compiled version of OpenDAL.\nOperation for <code>crate::raw::Access::write</code>\nPresign a write operation.\nWriter is the associated writer returned in <code>write</code> …\nProviding adapters and its implementations.\nGet the append from op.\nConsume the input and generate a request with multipart …\nInvoke the <code>batch</code> operations.\nInvoke the <code>batch</code> operations.\nDyn version of <code>Accessor::batch</code>\nInvoke the <code>blocking_copy</code> operation on the specified <code>from</code> …\nInvoke the <code>blocking_copy</code> operation on the specified <code>from</code> …\nDyn version of <code>Accessor::blocking_copy</code>\nInvoke the <code>blocking_create</code> operation on the specified path.\nInvoke the <code>blocking_create</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_create_dir</code>\nInvoke the <code>blocking_delete</code> operation on the specified path.\nInvoke the <code>blocking_delete</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_delete</code>\nInvoke the <code>blocking_list</code> operation on the specified path.\nInvoke the <code>blocking_list</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_list</code>\nInvoke the <code>blocking_read</code> operation on the specified path.\nInvoke the <code>blocking_read</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_read</code>\nInvoke the <code>blocking_rename</code> operation on the specified <code>from</code> …\nInvoke the <code>blocking_rename</code> operation on the specified <code>from</code> …\nDyn version of <code>Accessor::blocking_rename</code>\nInvoke the <code>blocking_stat</code> operation on the specified path.\nInvoke the <code>blocking_stat</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_stat</code>\nInvoke the <code>blocking_write</code> operation on the specified path.\nInvoke the <code>blocking_write</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_write</code>\nBuild a new http client in async context.\nbuild_abs_path will build an absolute path with root.\nBuild header value from given string.\nbuild_rel_path will build a relative path towards root.\nbuild_rooted_abs_path will build an absolute path with …\nGet the cache control from option\nGet chunk from option\nGet the chunk from op.\nDrop all tasks.\nGet the async client from http client.\nGet the concurrent of list operation.\nGet concurrent from option\nGet the concurrent.\nSet the content for this part.\nSet the content for this part.\nGet the content disposition from option\nGet the content type from option\nInvoke the <code>copy</code> operation on the specified <code>from</code> path and <code>to</code>…\nInvoke the <code>copy</code> operation on the specified <code>from</code> path and <code>to</code>…\nDyn version of <code>Accessor::copy</code>\nCreate a dir by parent_id and name.\nInvoke the <code>create</code> operation on the specified path\nInvoke the <code>create</code> operation on the specified path\nDyn version of <code>Accessor::create_dir</code>\nInvoke the <code>delete</code> operation on the specified path.\nInvoke the <code>delete</code> operation on the specified path.\nDyn version of <code>Accessor::delete</code>\nEnsure input dir exists.\nGet expire from op.\nformat will generates the bytes.\nformat authorization header by basic auth.\nformat authorization header by bearer token.\nformat content md5 header by given input.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nBuild a mixed part from a request.\nGet service’s full capabilities.\nGet service’s full capabilities.\nGet gap from option\nGet the id for the given path.\nGet basename from path.\nGet parent from path.\nReturn true if there is remaining space to push new …\nInsert a header into part.\nInsert a header into part.\nReturn request’s header.\nGet If-Match from option\nGet If-Match from option\nGet If-None-Match from option\nGet If-None-Match from option\nInvoke the <code>info</code> operation to get metadata of accessor.\nDyn version of <code>Accessor::info</code>\nInsert a new cache entry.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConsume RpStat to get the inner metadata.\nConsume OpBatch into BatchOperation\nConsume OpPresign into (Duration, PresignOperation)\nInto parts.\nConsume reply to build a presigned request.\nConsume a mixed part to build a response.\nConsume RpBatch to get the batched results.\nConvert self into static str.\nReturn true if there is no futures in the queue.\nCheck if this range is full of this content.\nIntercept the operations on the underlying storage.\nReturn the length of current concurrent futures (both …\nGet the length that specified by this BytesContentRange, …\nGet the limit of list operation.\nInvoke the <code>list</code> operation on the specified path.\nInvoke the <code>list</code> operation on the specified path.\nDyn version of <code>Accessor::list</code>\nOperate on inner metadata.\nGet the current metakey.\nSet the method for request in this part.\nReturn request’s method.\nName of backend, could be empty if underlying backend doesn…\nGet backend’s native capabilities.\nCreate a new path cacher.\nCreate a new RpBatch.\nCreate a new part builder\nCreate a new mixed part with given uri.\nCreate a new config deserializer.\nCreate a new ConcurrentFutures by specifying the number of …\nCreate a new reply for <code>presign</code>.\nCreate a new PresignedRequest\nCreate a new reply for <code>read</code>.\nCreate a new reply for <code>stat</code>.\nCreate a new reply for <code>write</code>.\nCreate a new reply for <code>copy</code>.\nCreate a new reply for <code>rename</code>.\nCreate a new <code>OpCreateDir</code>.\nCreate a new <code>OpDelete</code>.\nCreate a new <code>OpList</code>.\nCreate a new <code>OpPresign</code>.\nCreate a new batch options.\nCreate a default <code>OpRead</code> which will read whole content of …\nCreate a new <code>OpReader</code>.\nCreate a new <code>OpStat</code>.\nCreate a new <code>OpWrite</code>.\nCreate a new <code>OpCopy</code>.\nCreate a new <code>OpMove</code>.\nCreate a new http client in async context.\nCreate a new <code>BytesRange</code>\nCreate a new multipart with random boundary.\nParse json deserialize error into opendal::Error.\nParse json serialize error into opendal::Error.\nCreate a new error happened during building request.\nCreate a new error happened during signing request.\nCreate a new error happened during signing request.\nParse std io error into opendal::Error.\nParse tokio error into opendal::Error.\nParse xml deserialize error into opendal::Error.\nMake sure all operation are constructed by normalized path:\nMake sure root is normalized to style like <code>/abc/def/</code>.\nGet offset of BytesRange.\n<code>oio</code> provides OpenDAL’s raw traits and types that opendal …\nGet operation from op.\nGet operation from op.\nReturn the operation of this batch.\nReturns the cache-control header that should be send back …\nReturns the cache-control header that should be send back …\nReturns the content-disposition header that should be send …\nReturns the content-disposition header that should be send …\nReturns the content-type header that should be send back …\nReturns the content-type header that should be send back …\nparse will parse the bytes into a part.\nTODO\nParse a response with multipart body into Multipart.\nParse Content-Disposition for header map\nParse content encoding from header map.\nParse content length from header map.\nParse content md5 from header map.\nParse content range from header map.\nParse content type from header map.\nparse datetime from given timestamp\nparse datetime from given timestamp_millis\nParse dateimt from rfc2822.\nParse dateimt from rfc3339.\nParse etag from header map.\nParse header value to string according to name.\nparse_into_metadata will parse standards http headers into …\nParse last modified from header map.\nParse redirect location from header map\nInsert a part into multipart.\nInsert a part header into part.\npercent_decode_path will do percent decoding for http …\npercent_encode_path will do percent encoding for http …\nInvoke the <code>presign</code> operation on the specified path.\nInvoke the <code>presign</code> operation on the specified path.\nDyn version of <code>Accessor::presign</code>\nPush new future into the end of queue.\nPush new future into the start of queue, this task will be …\nQuery the id by parent_id and name.\nGot the range of the reader returned by this read …\nGet range from option\nGet the range inclusive of this BytesContentRange, return …\nGet the range inclusive of this BytesContentRange, return …\nInvoke the <code>read</code> operation on the specified path, returns a …\nInvoke the <code>read</code> operation on the specified path, returns a …\nDyn version of <code>Accessor::read</code>\nGet the current recursive.\nReturn the number of remaining space to push new futures.\nRemove a cache entry.\nInvoke the <code>rename</code> operation on the specified <code>from</code> path and …\nInvoke the <code>rename</code> operation on the specified <code>from</code> path and …\nDyn version of <code>Accessor::rename</code>\nGet the results from RpBatch.\nFetch the id for the root of the service.\nRoot of backend, will be in format like <code>/path/to/dir/</code>\n<code>Scheme</code> of backend.\nSend a request in async way.\nSet name of this backend.\nSet native capabilities for service.\nSet root for backend.\nSet <code>Scheme</code> for backend.\nGot the size of the reader returned by this read operation.\nGet size of BytesRange.\nGet the size of this BytesContentRange, return <code>None</code> if …\nGet the start_after of list operation.\nInvoke the <code>stat</code> operation on the specified path.\nInvoke the <code>stat</code> operation on the specified path.\nDyn version of <code>Accessor::stat</code>\nUtilities for opendal testing.\nConvert bytes range into Range header.\nConvert bytes content range into Content-Range header.\nConvert bytes range into rust range.\nReturn request’s uri.\nValidate given path is match with given EntryMode.\nSet the version for request in this part.\nGet the version of this delete operation.\nGet version from option\nGet version from option\nConstruct <code>Self</code> with given <code>reqwest::Client</code>\nSet the append mode of op.\nSet the boundary with given string.\nSet the content type of option\nSet the chunk of the option\nSet the chunk of op.\nChange the concurrent of this list operation.\nSet the concurrent of the option\nSet the maximum concurrent write task amount.\nSet the content disposition of option\nSet the content type of option\nAdd response context to error.\nSet the gap of the option\nSet the If-Match of the option\nSet the If-Match of the option\nSet the If-None-Match of the option\nSet the If-None-Match of the option\nChange the limit of this list operation.\nEnable the lock for the path cacher.\nChange the metakey of this list operation.\nSets the cache-control header that should be send back by …\nSets the cache-control header that should be send back by …\nSets the content-disposition header that should be send …\nSets the content-disposition header that should be send …\nSets the content-type header that should be send back by …\nSets the content-type header that should be send back by …\nSet the range of the reader returned by this read …\nSet the range of the option\nUpdate BytesContentRange with range.\nThe recursive is used to control whether the list …\nSet the size of the reader returned by this read operation.\nUpdate BytesContentRange with size.\nChange the start_after of this list operation.\nChange the version of this delete operation.\nSet the version of the option\nSet the version of the option\nInvoke the <code>write</code> operation on the specified path, returns a\nInvoke the <code>write</code> operation on the specified path, returns a\nDyn version of <code>Accessor::write</code>\nProviding Key Value Adapter for OpenDAL.\nProviding Typed Key Value Adapter for OpenDAL.\nKvAdapter is the adapter to underlying kv services.\nBackend of kv service. If the storage service is one …\nMetadata for this key value accessor.\nAppend a key into service\nAppend a key into service\nAppend a key into service in blocking way.\nAppend a key into service in blocking way.\nDelete a key from service in blocking way.\nDelete a key from service in blocking way.\nThe blocking version of get.\nThe blocking version of get.\nScan a key prefix to get all keys that start with this key …\nScan a key prefix to get all keys that start with this key …\nThe blocking version of set.\nThe blocking version of set.\nGet the capabilities.\nDelete a key from service.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet a key from service.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturn the metadata of this key value accessor.\nGet the name.\nCreate a new KeyValueAccessorInfo.\nCreate a new kv backend.\nScan a key prefix to get all keys that start with this key.\nScan a key prefix to get all keys that start with this key.\nGet the scheme.\nSet a key into service.\nConfigure root within this backend.\nAdapter is the typed adapter to underlying kv services.\nThe typed kv backend which implements Accessor for typed …\nCapability is used to describe what operations are …\nInfo for this key value accessor.\nValue is the typed value stored in adapter.\nDelete a value from adapter.\nGet a value from adapter.\nScan a key prefix to get all keys that start with this key …\nScan a key prefix to get all keys that start with this key …\nSet a value into adapter.\nGet the capabilities.\nDelete a value from adapter.\nIf typed_kv operator supports delete natively.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet a value from adapter.\nIf typed_kv operator supports get natively.\nGet the scheme and name of current adapter.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nMetadata of this value.\nGet the name.\nCreate a new KeyValueAccessorInfo.\nCreate a new kv backend.\nCreate a new dir of value.\nScan a key prefix to get all keys that start with this key.\nScan a key prefix to get all keys that start with this key.\nIf typed_kv operator supports scan natively.\nGet the scheme.\nSet a value into adapter.\nIf typed_kv operator supports set natively.\nSize returns the in-memory size of Value.\nThe corresponding content of this value.\nConfigure root within this backend.\nOperation for <code>Write::abort</code>\nAppendWrite is used to implement [<code>Write</code>] based on append …\nAppendWriter will implements [<code>Write</code>] based on append …\nBlockWrite is used to implement [<code>Write</code>] based on block …\nBlockWriter will implements [<code>Write</code>] based on block uploads.\nOperation for <code>BlockingWrite::close</code>\nBlockingList is the blocking version of <code>List</code>.\nBlockingLister is a boxed <code>BlockingList</code>\nOperation for <code>BlockingList::next</code>\nRead is the trait that OpenDAL returns to callers.\nOperation for [<code>BlockingRead::read</code>]\nBlockingReader is a boxed dyn <code>BlockingRead</code>.\nBlockingWrite is the trait that OpenDAL returns to callers.\nOperation for <code>BlockingWrite::write</code>\nBlockingWriter is a type erased <code>BlockingWrite</code>\nChunkedWriter is used to implement <code>oio::Write</code> based on …\nOperation for <code>Write::close</code>\nEntry is returned by <code>Page</code> or <code>BlockingPage</code> during list …\nFlatLister will walk dir in bottom up way:\nFlexBuf is a buffer that support frozen bytes and reuse …\nToHierarchyLister will convert a flat list to hierarchy by …\nPage trait is used by <code>raw::Accessor</code> to implement <code>list</code> …\nPageOperation is the name for APIs of lister.\nThe boxed version of <code>List</code>\nThe result of <code>MultipartWrite::write_part</code>.\nMultipartWrite is used to implement [<code>Write</code>] based on …\nMultipartWriter will implements [<code>Write</code>] based on multipart …\nOperation for <code>List::next</code>\nOneShotWrite is used to implement [<code>Write</code>] based on one …\nOneShotWrite is used to implement [<code>Write</code>] based on one …\nPageContext is the context passing between <code>PageList</code>.\nPageList is used to implement [<code>List</code>] based on API …\nPageLister implements [<code>List</code>] based on <code>PageList</code>.\nPooledBuf is a buffer pool that designed for reusing …\nPrefixLister is used to filter entries by prefix.\nQueueBuf is a queue of <code>Buffer</code>.\nRangeWrite is used to implement [<code>Write</code>] based on range …\nRangeWriter will implements [<code>Write</code>] based on range write.\nRead is the internal trait used by OpenDAL to read data …\nOperation for [<code>Read::read</code>]\nReadDyn is the dyn version of <code>Read</code> make it possible to use …\nPageOperation is the name for APIs of lister.\nReader is a type erased <code>Read</code>.\nWrite is the trait that OpenDAL returns to callers.\nOperation for <code>Write::write</code>\nWriteOperation is the name for APIs of Writer.\nWriter is a type erased <code>Write</code>\nAbort the pending writer.\nabort_block will cancel the block upload and purge all …\nabort_part will cancel the multipart upload and purge all …\nabort_range will abort the range write by abort all …\nPanics\nAdvance the buffer queue by <code>cnt</code> bytes.\nAppend the data to the end of this object.\nCleanup the buffer, reset to the initial state.\nClear the buffer queue.\nClose the writer and make sure all data has been flushed.\nClose the writer and make sure all data has been flushed.\nBuild a new <code>Buffer</code> from the queue.\ncomplete_block will complete the block upload to build the …\ncomplete_part will complete the multipart upload to build …\ncomplete_range will complete the range write by uploading …\ndone is used to indicate whether the list operation is …\nentries is used to store entries fetched from underlying …\nThe etag of the part.\nFreeze the buffer no matter it’s full or not.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet the frozen buffer.\nGet a <code>BytesMut</code> from the pool.\ninitiate_part will call start a multipart upload and …\nInitiate range the range write, the returning value is the …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConvert self into static str.\nConvert self into static str.\nConvert self into static str.\nIs the buffer queue empty.\nTotal bytes size inside the buffer queue.\nGet entry’s mode.\nCreate a new MultipartWriter.\nCreate a new AppendWriter.\nCreate a new one shot writer.\nCreate a new exact buf writer.\nCreate a new MultipartWriter.\nCreate a new BlockWriter.\nCreate a new PageLister.\nCreate a new flat lister\nCreate a new hierarchy lister\nCreate a new flat lister\nInitializes a new <code>FlexBuf</code> with the given capacity.\nCreate a new buffer pool with a given size.\nCreate a new entry by its corresponding underlying storage.\nCreate a new buffer queue.\nFetch a new page of <code>Entry</code>\nFetch a new page of <code>Entry</code>\nnext_page is used to fetch next page of entries from …\nGet the current offset of the append object.\nThe number of the part, starting from 0.\nGet the path of entry.\nPush new <code>Buffer</code> into the queue.\nPut slice into flex buf.\nPut a <code>BytesMut</code> back to the pool.\nRead at the given offset with the given limit.\nRead data from the reader at the given offset with the …\nThe dyn version of <code>Read::read_at</code>.\nSet mode for entry.\nSet path for entry.\ntoken is used by underlying storage services to fetch next …\nCreate a new entry with given value.\nSet the initial capacity of the buffer.\nWrite given bytes into writer.\nWrite whole content at once.\nwrite_block will write a block of the data and returns the …\nwrite_once is used to write the data to underlying storage …\nwrite_once write all data at once.\nwrite_once is used to write the data to underlying storage …\nwrite_once is used to write the data to underlying storage …\nwrite_part will write a part of the data and returns the …\nwrite_range will write a range of data.\nRead represents a read action with given input buf size.\nReadAction represents a read action.\nReadChecker is used to check the correctness of the read …\nTEST_RUNTIME is the runtime used for running tests.\nWrite represents a write action with given input buf size.\nWriteAction represents a read action.\nWriteAction is used to check the correctness of the write …\nCheck will check the correctness of the read process via …\nCheck will check the correctness of the read process via …\nCheck the correctness of the write process.\nGet the check’s chunks.\nReturn the raw data of this read checker.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nInit a service with given scheme.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate a new read checker by given size and range.\nCreate a new WriteChecker with given size.\nAlluxio services support.\nConfig for alluxio services support.\nCapabilities\nAtomicserver service support. Config for Atomicserver …\nCapabilities\nAzure Storage Blob services support.\nAzure Data Lake Storage Gen2 Support. As known as <code>abfs</code>, …\nAzure File services support.\nb2 services support.\nConfig for backblaze b2 services support.\ncacache service support.\nchainsafe services support.\nConfig for backblaze Chainsafe services support.\nCapabilities\n<code>compio</code>-based file system support.\nTencent-Cloud COS services support.\nCapabilities\nConfig for Cloudflare D1 backend support.\ndashmap backend support.\nDbfs’s REST API support. This service will visit the …\nDropbox backend support.\nConfig for Dropbox backend support.\nEtcd services support.\nConfig for Etcd services support.\nfoundationdb service support. Config for FoundationDB.\nCapabilities\nPOSIX file system support.\nFTP and FTPS services support.\nConfig for Ftpservices support.\nGoogle Cloud Storage services support.\nGoogle Cloud Storage services support.\nGoogleDrive backend support.\nGitHub Action Cache Services support.\ngithub contents services support.\nConfig for backblaze Github services support.\nCapabilities\nA distributed file system that provides high-throughput …\nHadoop Distributed File System (HDFS™) support.\nA distributed file system that provides high-throughput …\nHadoop Distributed File System (HDFS™) support. Using …\nHTTP Read-only service support like Nginx and Caddy.\nConfig for Http service support.\nHuggingface’s API support. This service will visit the …\nConfiguration for Huggingface service support.\nIcloudDrive service support.\nIPFS file system support based on IPFS HTTP Gateway.\nIPFS file system support based on IPFS MFS API.\nKoofr services support.\nConfig for backblaze Koofr services support.\nCapabilities\nConfig for Libsqlservices support.\nMemcached service support.\nConfig for MemCached services support\nIn memory service support. (BTreeMap Based)\nConfig for memory.\nmini-moka backend support.\nmoka backend support.\nConfig for Mokaservices support.\nCapabilities\nConfig for Mongodb service support.\nCapabilities\nConfig for Mysql services support.\nHuawei-Cloud Object Storage Service (OBS) support\nOneDrive backend support.\nConfig for OneDrive backend support.\nAliyun Object Storage Service (OSS) support\npCloud services support.\nConfig for backblaze Pcloud services support.\npersy service support.\nPostgreSQL services support.\nConfig for PostgreSQL services support.\nRedb service support.\nRedis services support.\nConfig for Redis services support.\nRocksDB service support.\nConfig for Rocksdb Service.\nAws S3 and compatible services (including minio, …\nConfig for Aws S3 and compatible services (including …\nseafile services support.\nConfig for backblaze seafile services support.\nSFTP services support. (only works on unix)\nConfig for Sftp Service support.\nSled services support.\nConfig for Sled services support.\nCapabilities\nConfig for Sqlite support.\nSupabase service support\nCapabilities\nConfig for Surrealdb services support.\nOpenStack Swift’s REST API support. For more information …\nTiKV backend builder\nConfig for Tikv services support.\nupyun services support.\nConfig for backblaze upyun services support.\nVercel Cache backend support.\nVercelBlob services support.\nConfig for backblaze VercelBlob services support.\nWebDAV backend support.\nConfig for WebDAV backend support.\nWebHDFS’s REST API support. There two implementations of …\nYandexDisk services support.\nConfig for backblaze YandexDisk services support.\nSet access_key_id of this backend.\nSet access_key_id of this backend.\nSet access_key_id of this backend.\naccess_key_id of this backend.\nSet access_key_secret of this backend.\nset the bearer access token for OneDrive\nAccess token is used for temporary access to the …\nAccess token is used for temporary access to the Dropbox …\nset the bearer access token for Vercel\nyandex disk oauth access_token. The valid token will looks …\nbearer access token for OneDrive\naccess token for dropbox.\nyandex disk oauth access_token.\nSet the account ID used to authenticate with CloudFlare.\nSet the account identifier for the cloudflare d1 service.\nSet the account id of cloudflare api.\nSet account_key of this backend.\nSet account_key of this backend.\nSet account_key of this backend.\nThe account key of Azblob service backend.\nSet account_name of this backend.\nSet account_name of this backend.\nSet account_name of this backend.\nThe account name of Azblob service backend.\nAllow anonymous will allow opendal to send request without …\nAllow anonymous will allow opendal to send request without …\nAllow anonymous will allow opendal to send request without …\napi_key of this backend.\napi_key of this backend.\nYour Apple id\napplication_key of this backend.\napplicationKey of this backend.\napplication_key_id of this backend.\nkeyID of this backend.\nSet temp dir for atomic write.\nSet temp dir for atomic write.\nSet temp dir for atomic write.\natomic_write_dir of this backend\natomic_write_dir of this backend\nset the authentication token for libsql service.\nSet maximum batch operations of this backend.\nSet maximum batch operations of this backend.\nSet maximum batch operations of this backend.\nThe maximum batch operations of Azblob service backend.\nSet maximum batch operations of this backend.\nSet bucket of this backend. The param is required.\nset the container’s name\nSet the buctet name of the MongoDB GridFs service to …\nSet bucket of this backend. The param is required.\nSet bucket name of this backend.\nSet bucket name of this backend.\nSet bucket name of this backend.\nSet bucket name of this backend. You can find it in …\nbucket of this backend.\nbucket name of this backend.\nbucket of this backend.\nbucket address of this backend.\nSet bucket id of this backend. You can find it in …\nSet bucket_id name of this backend.\nbucket id of this backend.\nbucket_id of this backend.\nBuild a HuggingfaceBackend.\nbuild the backend\nBuilds the backend and returns the result of GithubBackend.\nBuild a DbfsBackend.\nBuild a SwiftBackend.\nBuilds the backend and returns the result of …\nBuilds the backend and returns the result of B2Backend.\nBuilds the backend and returns the result of …\nBuilds the backend and returns the result of UpyunBackend.\nBuilds the backend and returns the result of …\nBuilds the backend and returns the result of PcloudBackend.\nBuilds the backend and returns the result of …\nBuilds the backend and returns the result of KoofrBackend.\nBuilds the backend and returns the result of …\nSet the certificate authority file path.\nSet the certificate authority file path.\ncertificate authority file path\ncertificate authority file path\nSet the certificate file path.\nSet the certificate file path.\ncert path\ncert path\nSet checksum algorithm of this backend. This is necessary …\nChecksum Algorithm to use when sending checksums in HTTP …\nSet the chunk size of the MongoDB GridFs service used to …\nSet the client id for GoogleDrive.\nSet the client id for Dropbox.\nclient_id for dropbox.\nSet the client secret for GoogleDrive.\nSet the client secret for Dropbox.\nclient_secret for dropbox.\nset the network address of redis cluster service. This …\nSet the collection name of the MongoDB service to …\ncollection of this backend\nicloud config for web session request\nSet the config path for Foundationdb. If not set, will …\nconfig_path for the backend.\nSet the connection_string of the MongoDB service.\nSet the connection_string of the libsql service.\nSet the connection_string of the postgresql service.\nSet the connection_string of the mysql service.\nSet the connection_string of the sqlite service.\nSet the connection_string of the MongoDB service.\nSet the connection_string of the surrealdb service.\nSet the connection_string of the sqlite service.\nconnection string of this backend\nSet container name of this backend.\nSet container of this backend.\nThe container name of Azblob service backend.\nset the base64 hashed credentials string used for OAuth2 …\nset the local path to credentials file which is used for …\nAdding a customed credential load for service.\nSpecify the customed token loader used by this service.\nSet the database name of the MongoDB GridFs service to …\nSet the database name of the MongoDB service to read/write.\nSet the database of the surrealdb service for read/write.\ndatabase of this backend\nSet the database identifier for the cloudflare d1 service.\nSet the database id of cloudflare api.\nSet the path to the cacache data directory. Will create if …\nSet the path to the rocksdb data directory. Will create if …\nSet the path to the sled data directory. Will create if …\nSet the path to the redb data directory. Will create if …\nSet the path to the persy data directory. Will create if …\nset the db used in redis\nSet the default storage class for GCS.\nSet default storage_class for this backend.\ndefault storage_class for this backend.\nSet the default ttl for memcached services.\nSet the default ttl for redis services.\nSet the delegation token of this backend, used for …\nDetect region of S3 bucket.\nDisable config load so that opendal will not load config …\nDisable config load so that opendal will not load config …\nDisable config load so that opendal will not load config …\nWebDAV Service doesn’t support copy.\nDisable load credential from ec2 metadata.\nDisable load credential from ec2 metadata.\nDisable batch listing\nDisable stat with override so that opendal will not send …\nDisable stat with override so that opendal will not send …\nds_web_auth_token must be set in Session\nemail.\nKoofr email.\nEnable append capacity of this backend.\nEnable append capacity of this backend.\nenable the append capacity\nenable the append capacity\nset enable_copy for sftp backend. It requires the server …\nenable_copy of this backend\nEnable virtual host style so that opendal will send API …\nEnable virtual host style so that opendal will send API …\nSet encryption_algorithm of this backend.\nThe encryption algorithm of Azblob service backend.\nSet encryption_key of this backend.\nThe encryption key of Azblob service backend.\nSet encryption_key_sha256 of this backend.\nThe encryption key sha256 of Azblob service backend.\nSet endpoint of this backend\nSet endpoint of this backend.\nSet endpoint of this backend.\nset endpoint for ftp backend.\nset the endpoint GCS service uses\nSet the endpoint for ghac service.\nSet endpoint for http backend.\nSet endpoint if ipfs backend.\nSet endpoint for ipfs.\nset the network address of memcached service.\nSet endpoint of this backend.\nSet endpoint of this backend.\nset the network address of redis service.\nSet endpoint of this backend.\nset endpoint for sftp backend. The format is same as …\nSet endpoint of this backend.\nSet endpoint for http backend.\nSet the remote address of this backend default to …\nSet the server address for Atomicserver.\nSet endpoint of this backend.\nSet endpoint of this backend.\nSet the remote address of this backend\nendpoint of this backend.\nendpoint of this backend.\nPcloud endpoint. https://api.pcloud.com for United States …\nendpoint.\nThe endpoint of Azblob service backend.\nendpoint of this backend\nendpoint of this backend\nendpoint of this backend.\nendpoint of this backend\nendpoint of this backend\nendpoint of this backend\nendpoint of this backend.\nendpoint address of this backend.\npCloud  endpoint address.\nKoofr endpoint.\nset the network address of etcd service.\nSet the network address of the TiKV service.\nnetwork address of the Etcd services. If use https, must …\nnetwork address of the TiKV service.\nSet external_id for this backend.\nexternal_id for this backend.\nSet filesystem name of this backend.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nfrom_connection_string will make a builder from connection …\nConverts a HashMap into an GithubBuilder instance.\nConverts a HashMap into an AlluxioBuilder instance.\nConverts a HashMap into an B2Builder instance.\nConverts a HashMap into an SeafileBuilder instance.\nConverts a HashMap into an UpyunBuilder instance.\nConverts a HashMap into an ChainsafeBuilder instance.\nConverts a HashMap into an PcloudBuilder instance.\nConverts a HashMap into an YandexDiskBuilder instance.\nConverts a HashMap into an KoofrBuilder instance.\nConverts a HashMap into an VercelBlobBuilder instance.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSet the name of the persy index. Will create if not exists.\nSet the insecure connection to TiKV.\nwhether using insecure connection to TiKV\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nSet if your apple id in China mainland.\nSet kerberos_ticket_cache_path of this backend\nkerberos_ticket_cache_path of this backend\nset key path for sftp backend.\nSet the authorization key for this backend Do not set this …\nkey of this backend\nSet the key field name of the libsql service to read/write.\nSet the key field name of the postgresql service to …\nSet the key field name of the mysql service to read/write.\nSet the key field name of the sqlite service to read/write.\nSet the key field name of the d1 service to read/write.\nSet the key field name of the MongoDB service to …\nSet the key field name of the surrealdb service for …\nSet the key field name of the sqlite service to read/write.\nSet the key field of D1 Database.\nkey field of this backend\nSet the key file path.\nSet the key file path.\nkey path\nkey path\nset known_hosts strategy for sftp backend. available …\nknown_hosts_strategy of this backend\nSets the max capacity of the cache.\nSets the max capacity of the cache.\nSets the max capacity of the cache.\nName for this cache instance.\nName for this cache instance.\nSet name_node of this backend.\nname node of this backend\nSet the namespace of the surrealdb service for read/write.\nSet the namespace ID.\nSets the segments number of the cache.\noperator of this backend.\nusername of this backend.\nSet Github repo owner.\nGithub repo owner.\nSet the parent resource id (url) that Atomicserver uses to …\nparent_resource_id of this backend\nset the password for etcd\nset password for ftp backend.\nset password for http backend\nYour Apple id password\nset the password.\nset the password for redis\nset the password for Webdav\npassword of this backend.\npassword of this backend.\nPcloud password.\nKoofr application password.\nSet the password of the surrealdb service for signin.\nthe password for authentication\npassword of this backend\npassword of this backend\npassword of this backend\npassword of this backend.\npassword of this backend.\npCloud password.\npassword of this backend. (Must be the application …\nSet the predefined acl for GCS.\nSet a endpoint for generating presigned urls.\nSet the private key for agent used for Atomicserver.\nprivate_key of this backend\nSet the public key for agent used for Atomicserver. For …\npublic_key of this backend\nRefresh token is used for long term access to the …\nRefresh token is used for long term access to the Dropbox …\nrefresh_token for dropbox.\nRegion represent the signing region of this endpoint. This …\nRegion represent the signing region of this endpoint. This …\nSet Github repo name.\nGithub repo name.\nSet repo id of this backend. This is required.\nRepo id of this backend.\nSet repo name of this backend.\nrepo_name of this backend.\nSet repo type of this backend. Default is model.\nRepo type of this backend. Default is model.\nSet revision of this backend. Default is main.\nRevision of this backend.\nSet role_arn for this backend.\nrole_arn for this backend.\nSet root of this backend.\nSet root of this backend.\nSet the root within this backend.\nSet root of this backend.\nSet the root for dashmap.\nset the working directory, all operations will be …\nSet root for backend.\nset root path for ftp backend.\nset the working directory root of backend\nset the working directory root of backend\nSet the working directory, all operations will be …\nSet root of this backend.\nSet root path of http backend.\nSet root of this backend.\nSet root of ipfs backend.\nSet root for ipfs.\nSet root of this backend.\nset the working directory, all operations will be …\nset the working directory, all operations will be …\nSet the root for BTreeMap.\nSet root of this backend.\nSet root of this backend.\nset the working directory, all operations will be …\nset the working directory, all operations will be …\nSet root of this backend.\nset root path for sftp backend. It uses the default …\nSet the root for sled.\nSet root of this backend.\nSet root path of http backend.\nSet the working directory of this backend\nSet root path of OneDrive folder.\nSet root path of GoogleDrive folder.\nSet root of this backend.\nSet the root directory for dropbox.\nSet the root for Redb.\nSet the root for Foundationdb.\nset the working directory, all operations will be …\nSet the root for Atomicserver.\nset the working directory, all operations will be …\nset the working directory, all operations will be …\nset the working directory, all operations will be …\nSet root of this backend.\nSet the working directory, all operations will be …\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nset the working directory, all operations will be …\nSet root for Compfs\nThe root of Azblob service backend.\nthe working directory of the etcd service. Can be “…\nroot of this backend\nwork dir of this backend\nroot of this backend\nRoot of this backend. Can be “/path/to/dir”.\nroot of the backend.\nroot of this backend.\nroot of this backend\nroot of this backend\nroot path of OneDrive folder.\nroot of this backend.\nroot path for dropbox.\nroot of the backend.\nRoot of this backend.\nwork dir of this backend\nset the working directory, all operations will be …\nSet the working directory of OpenDAL.\nroot of this backend\nroot of this backend.\nroot of this backend.\nroot of this backend.\nroot of this backend.\nroot of this backend.\nroot of this backend.\nwork dir of this backend\nroot of this backend.\nroot of this backend.\nroot of this backend.\nSet the runtime token for ghac service.\nSet sas_token of this backend.\nThe sas token of Azblob service backend.\nset the GCS service scope\nSet secret_access_key of this backend.\nSet secret_access_key of this backend.\nsecret_access_key of this backend.\nSet secret_id of this backend.\nSet secret_key of this backend.\nSet temporary credential used in AWS S3 connections\nsecurity_token (aka, session token) of this backend.\nSet the name of the persy segment. Will create if not …\nSets the segments number of the cache.\nSet server_side_encryption for this backend.\nSet server_side_encryption for this backend.\nserver_side_encryption for this backend.\nSet server_side_encryption_aws_kms_key_id for this backend\nserver_side_encryption_aws_kms_key_id for this backend\nSet server_side_encryption_customer_algorithm for this …\nserver_side_encryption_customer_algorithm for this backend.\nSet server_side_encryption_customer_key for this backend.\nserver_side_encryption_customer_key for this backend.\nSet server_side_encryption_customer_key_md5 for this …\nSet server_side_encryption_customer_key_md5 for this …\nSet server_side_encryption_key_id for this backend.\nEnable server side encryption with aws managed kms key\nEnable server side encryption with customer key.\nEnable server side encryption with customer key.\nEnable server side encryption with customer managed kms key\nEnable server side encryption with s3 managed key\nSet the GCS service account.\nSet file share name of this backend.\nSet the table name of the libsql service to read/write.\nSet the table name for Redb.\nSet the table name of the postgresql service to read/write.\nSet the table name of the mysql service to read/write.\nSet the table name of the sqlite service to read/write.\nSet the table name of the d1 service to read/write.\nSet the table name of the surrealdb service for read/write.\nSet the table name of the sqlite service to read/write.\nSet the table of D1 Database.\nSets the time to idle of the cache.\nSets the time to idle of the cache.\nSets the time to idle of the cache.\nSets the time to live of the cache.\nSets the time to live of the cache.\nSets the time to live of the cache.\nSet the token used to authenticate with CloudFlare.\nset bearer token for http backend\nSet the token of this backend.\nset the bearer token for Webdav\nGithub access_token.\nSet api token for the cloudflare d1 service.\nSet the token of this backend.\nSet the token of this backend.\nVercel Blob token.\ntoken of this backend\nToken of this backend.\ntoken of this backend\nGithub access_token.\nSet the token of cloudflare api.\nvercel blob token.\nSet the tree for sled.\nTrust token and ds_web_auth_token is used for temporary …\nSet url of this backend.\nurl of this backend\nset user for ftp backend.\nSet user of this backend\nset user for sftp backend.\nuser of this backend\nuser of this backend\nuser of this backend\nset the username for etcd\nset username for http backend\nset the username.\nset the username for redis\nset the username for Webdav\nusername of this backend.\nPcloud username.\nSet the username of the surrealdb service for signin.\nthe username to connect etcd service.\nusername of this backend\nusername of this backend\nusername of this backend.\npCloud username.\nSet the value field name of the libsql service to …\nSet the value field name of the postgresql service to …\nSet the value field name of the mysql service to …\nSet the value field name of the sqlite service to …\nSet the value field name of the d1 service to read/write.\nSet the value field name of the MongoDB service to …\nSet the value field name of the surrealdb service for …\nSet the value field name of the sqlite service to …\nSet the value field of D1 Database.\nvalue field of this backend\nset the version that used by cache.")